* exact algorithm is not practical for a dense graph

  Consider a full graph of one timeline with n features.

  For n=20, We would need

  #+BEGIN_SRC python
  def memoize(f):
      d = {}
      def f_(n):
          if n in d: return d[n]
          d[n] = f(n)
          return d[n]
          
      return f_
  
  @memoize
  def T(n):
      if n == 1: return 1
      return sum([T(i) for i in range(1, n)]) + 1

  return T(20)
  #+END_SRC

  #+RESULTS:
  : 524288

  many paths for a single ordering of the graph.This doesn't even count for the
  number of possible permutations of the paths, which in the worst case can be
  $O((n+1)!)$.

  Exact algorithm for this scenario wouldn't be practical. Therefore one need to
  use approximations. Like computing regular Shapley value, one can use
  sampling. However, unlike regular Shapley value, only sampling different
  timelines is not enough because we saw that even a single ordering can be
  prohibitive. We need to sample for the different path.
  
  A hand wavy description of the sampling procedure is the following:

  - sample a source to target path to compute attribution
  - follow edges in the path from the source to the target; for each edge
    - making all input visible, set its sources' non active branches to random
      values and propagate its values downwards (run the eval function following a
      topological ordering)
    - compute the new value for the edge's sink node, assuming all inputs are visible
  - attribute the change output to the path

  Note that each sampling requires at most $n$ evaluation of the graph because
  the path length is at most $n$. This is a lot cheaper
  
* efficient for balanced tree with small branching factor

  For a balanced tree with n nodes, with a branching factor b

  #+begin_example
  T(n) = (b * 2^b) T(n/b) + O(b)
       = k (k T(n/b^2) + O(b)) + O(b)
       = O(b) + O(bk) + ... + O(b k^(log_b(n)))
  #+end_example

  where ~k=b * 2^b~ comes from the fact that at each level, we are computing the
  importance for b nodes, trying all 2^b combinations. O(b) comes from the fact
  that we are adding the importance of b nodes together to get the importance of
  the top node.

  T(n) is clearly dominated by the last term, solving for it yield

  #+begin_example
  T(n) = O((b * 2^b)^(log_b(n)))
       = O(2^{(log_2(b) + b) * log_2(n) / log_2(b)})
       = O(2^{log_2(n^{1 + b/log_2(b)})})
       = O(n^(1 + b/log_2(b)))
  #+end_example
  
  If b is small, T(n) is a small polynomial in n. When b=2, T(n) = O(n^2), which
  is the time complexity of the partition explainer in ~SHAP~.

  This is a vast improvement over the $O(2^n)$ complexity of flat Shapley value.


